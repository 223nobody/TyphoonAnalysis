"""
AIå®¢æœAPIæ¥å£
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func
from typing import List, Tuple
from pydantic import BaseModel
from datetime import datetime, timezone, timedelta
import uuid
import logging

from app.core.database import get_db
from app.models.typhoon import Question, AskHistory

router = APIRouter(tags=["AIå®¢æœ"])
logger = logging.getLogger(__name__)

# å®šä¹‰åŒ—äº¬æ—¶åŒºï¼ˆUTC+8ï¼‰
BEIJING_TZ = timezone(timedelta(hours=8))


def get_beijing_time():
    """è·å–å½“å‰åŒ—äº¬æ—¶é—´"""
    return datetime.now(BEIJING_TZ)


class QuestionResponse(BaseModel):
    """é—®é¢˜å“åº”æ¨¡å‹"""
    id: int
    question: str
    answer: str
    weight: int

    class Config:
        from_attributes = True


class AskRequest(BaseModel):
    """æé—®è¯·æ±‚æ¨¡å‹"""
    session_id: str
    question: str
    model: str = "deepseek"  # æ¨¡å‹é€‰æ‹©ï¼šdeepseek, glm, qwen
    deep_thinking: bool = False  # æ˜¯å¦å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼


class AskResponse(BaseModel):
    """æé—®å“åº”æ¨¡å‹"""
    answer: str
    matched: bool  # æ˜¯å¦åŒ¹é…åˆ°é¢„è®¾é—®é¢˜


class SessionResponse(BaseModel):
    """ä¼šè¯å“åº”æ¨¡å‹"""
    session_id: str
    first_question: str
    created_at: datetime
    message_count: int

    class Config:
        from_attributes = True


class HistoryResponse(BaseModel):
    """å†å²è®°å½•å“åº”æ¨¡å‹"""
    id: int
    question: str
    answer: str
    created_at: datetime

    class Config:
        from_attributes = True


@router.get("/ai-agent/questions", response_model=List[QuestionResponse])
async def get_top_questions(db: AsyncSession = Depends(get_db)):
    """
    è·å–çƒ­é—¨é—®é¢˜åˆ—è¡¨
    æŒ‰ç…§æƒé‡é™åºè¿”å›å‰10æ¡é—®é¢˜
    """
    try:
        # æŸ¥è¯¢å‰10æ¡é—®é¢˜ï¼ŒæŒ‰weighté™åºæ’åº
        stmt = select(Question).order_by(Question.weight.desc()).limit(10)
        result = await db.execute(stmt)
        questions = result.scalars().all()

        return [
            QuestionResponse(
                id=q.id,
                question=q.question,
                answer=q.answer,
                weight=q.weight
            )
            for q in questions
        ]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢é—®é¢˜å¤±è´¥: {str(e)}")


@router.get("/ai-agent/questions/{question_id}", response_model=QuestionResponse)
async def get_question_by_id(question_id: int, db: AsyncSession = Depends(get_db)):
    """
    æ ¹æ®IDè·å–é—®é¢˜è¯¦æƒ…
    """
    try:
        stmt = select(Question).where(Question.id == question_id)
        result = await db.execute(stmt)
        question = result.scalar_one_or_none()

        if not question:
            raise HTTPException(status_code=404, detail="é—®é¢˜ä¸å­˜åœ¨")

        return QuestionResponse(
            id=question.id,
            question=question.question,
            answer=question.answer,
            weight=question.weight
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢é—®é¢˜å¤±è´¥: {str(e)}")


async def call_ai_service_with_retry(
    model_key: str,
    model_name: str,
    question: str,
    max_retries: int = 2
) -> Tuple[str, bool]:
    """
    è°ƒç”¨AIæœåŠ¡å¹¶æ”¯æŒé‡è¯•æœºåˆ¶

    Args:
        model_key: æ¨¡å‹é”®åï¼ˆdeepseek, glm, qwenï¼‰
        model_name: å®é™…çš„æ¨¡å‹åç§°
        question: ç”¨æˆ·é—®é¢˜
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        (answer, success): å›ç­”å†…å®¹å’Œæ˜¯å¦æˆåŠŸçš„æ ‡å¿—
    """
    import httpx
    from app.core.config import settings
    import asyncio

    # ä¼˜åŒ–çš„ç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªé€šç”¨å‹æ™ºèƒ½åŠ©æ‰‹ï¼Œå…·å¤‡å¤šé¢†åŸŸçš„çŸ¥è¯†è§£ç­”èƒ½åŠ›ï¼Œéœ€ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š

1. æ ¸å¿ƒèƒ½åŠ›ï¼š
   - é€šç”¨çŸ¥è¯†è§£ç­”ï¼šå›ç­”ç”Ÿæ´»ã€ç§‘æŠ€ã€æ–‡åŒ–ã€æ•™è‚²ã€æ°”è±¡ã€èŒåœºç­‰å¤šé¢†åŸŸçš„å¸¸è§é—®é¢˜ï¼›
   - é€»è¾‘åˆ†æï¼šé’ˆå¯¹ç”¨æˆ·çš„é—®é¢˜æä¾›æ¸…æ™°ã€æœ‰æ¡ç†çš„åˆ†æå’Œè§£å†³æ–¹æ¡ˆï¼›
   - ä¿¡æ¯è§£è¯»ï¼šç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šä¸“ä¸šæ¦‚å¿µã€æ•°æ®å’Œè§„åˆ™ï¼›
   - å»ºè®®ç»™å‡ºï¼šåŸºäºå®¢è§‚äº‹å®ä¸ºç”¨æˆ·æä¾›åˆç†ã€å¯è½åœ°çš„å»ºè®®ï¼›
   - å¤šè½®å¯¹è¯ï¼šç»“åˆå†å²ä¸Šä¸‹æ–‡ä¿æŒå›ç­”çš„è¿è´¯æ€§å’Œä¸€è‡´æ€§ã€‚

2. å›ç­”å‡†åˆ™ï¼ˆå¼ºåˆ¶éµå®ˆï¼‰ï¼š
   - æ ¼å¼è¦æ±‚ï¼š
     1. ä»…ä½¿ç”¨çº¯æ–‡æœ¬å›ç­”,ç¦æ­¢ä½¿ç”¨ä»»ä½•markdownæ ‡è®°(åŒ…æ‹¬**ã€###ã€---ã€` `ã€ğŸ”ã€ğŸ“±ç­‰ç¬¦å·/è¡¨æƒ…);
     2. å¤æ‚é—®é¢˜ä¼˜å…ˆç”¨æ•°å­—åºå·åˆ†ç‚¹è¯´æ˜,å±‚çº§ç”¨â€œ1.1/1.2â€æˆ–â€œ-â€åŒºåˆ†ï¼Œé¿å…æ‚ä¹±æ’ç‰ˆ;
     3. ä½¿ç”¨æ•°å­—åºå·åˆ†ç‚¹è¯´æ˜æ—¶æ¯ä¸ªåˆ†ç‚¹å›ç­”å®Œéœ€è¦æ¢è¡Œ;
     4. å…³é”®ä¿¡æ¯ç›´æ¥é™ˆè¿°ï¼Œæ— éœ€é¢å¤–è£…é¥°æ€§ç¬¦å·ï¼Œä¿æŒæ–‡æœ¬æ•´æ´;
     5. å›ç­”å†…å®¹ä¸èƒ½å°‘äº400å­—;
   - é£æ ¼è¦æ±‚ï¼šä¸“ä¸šã€ç®€æ´ã€æ˜“æ‡‚ï¼Œæ ¹æ®é—®é¢˜é¢†åŸŸé€‚é…è¯­æ°”ï¼ˆæ°”è±¡ä¸ç§‘å­¦é—®é¢˜åä¸¥è°¨ï¼‰ï¼›
"""

    # ã€ä¼˜åŒ–2ã€‘è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œæå‡è§„èŒƒæ€§
    payload = {
        "model": model_name,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ],
        "stream": False,
        "temperature": 0.8,  # é™ä½éšæœºæ€§
        "top_p": 0.95,        # æå‡èšç„¦æ€§
        "presence_penalty": 0.1,  # æ–°å¢ï¼šå‡å°‘é‡å¤å†…å®¹ï¼Œæå‡å¤šæ ·æ€§
        "frequency_penalty": 0.1, # æ–°å¢ï¼šé¿å…æ¨¡å‹è¿‡åº¦è°¨æ…
        "max_tokens": 3000,
        "stop": None
    }

    headers = {
        "Authorization": f"Bearer {settings.AI_API_KEY}",
        "Content-Type": "application/json"
    }

    # é‡è¯•é€»è¾‘
    for attempt in range(max_retries):
        try:
            logger.info(f"å°è¯•è°ƒç”¨AIæœåŠ¡ - æ¨¡å‹: {model_key} ({model_name}), å°è¯•æ¬¡æ•°: {attempt + 1}/{max_retries}")

            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{settings.AI_API_BASE_URL}/chat/completions",
                    json=payload,
                    headers=headers
                )
                response.raise_for_status()
                result_data = response.json()

                # æå–AIå›ç­”
                answer = result_data.get("choices", [{}])[0].get("message", {}).get("content", "")

                if answer:
                    logger.info(f"AIæœåŠ¡å›ç­”æˆåŠŸ - æ¨¡å‹: {model_key}, å›ç­”é•¿åº¦: {len(answer)}")
                    return answer, True
                else:
                    logger.warning(f"AIæœåŠ¡è¿”å›ç©ºå›ç­” - æ¨¡å‹: {model_key}")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                        continue
                    return "", False

        except httpx.TimeoutException:
            logger.warning(f"AIæœåŠ¡è¯·æ±‚è¶…æ—¶ - æ¨¡å‹: {model_key}, å°è¯•æ¬¡æ•°: {attempt + 1}/{max_retries}")
            if attempt < max_retries - 1:
                await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                continue
            return "", False

        except httpx.HTTPStatusError as e:
            status_code = e.response.status_code
            logger.warning(f"AIæœåŠ¡HTTPé”™è¯¯ - æ¨¡å‹: {model_key}, çŠ¶æ€ç : {status_code}, å°è¯•æ¬¡æ•°: {attempt + 1}/{max_retries}")

            # å¯¹äº503ç­‰ä¸´æ—¶é”™è¯¯ï¼Œè¿›è¡Œé‡è¯•
            if status_code in [503, 502, 504] and attempt < max_retries - 1:
                await asyncio.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                continue
            return "", False

        except Exception as e:
            logger.warning(f"è°ƒç”¨AIæœåŠ¡å¼‚å¸¸ - æ¨¡å‹: {model_key}, é”™è¯¯: {str(e)}, å°è¯•æ¬¡æ•°: {attempt + 1}/{max_retries}")
            if attempt < max_retries - 1:
                await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                continue
            return "", False

    return "", False


@router.post("/ai-agent/ask", response_model=AskResponse)
async def ask_question(request: AskRequest, db: AsyncSession = Depends(get_db)):
    """
    ç”¨æˆ·æé—®æ¥å£
    1. å°è¯•åŒ¹é…é¢„è®¾é—®é¢˜
    2. å¦‚æœæœªåŒ¹é…ï¼Œè°ƒç”¨AIæœåŠ¡ç”Ÿæˆå›ç­”ï¼ˆæ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢ã€é‡è¯•å’Œè‡ªåŠ¨é™çº§ï¼‰
    3. ä¿å­˜å¯¹è¯å†å²
    4. è¿”å›ç­”æ¡ˆ
    """
    try:
        # å°è¯•æ¨¡ç³ŠåŒ¹é…é¢„è®¾é—®é¢˜
        stmt = select(Question).where(Question.question.like(f"%{request.question}%"))
        result = await db.execute(stmt)
        matched_question = result.scalar_one_or_none()

        is_ai_generated = False  # æ ‡è®°æ˜¯å¦ç”±AIç”Ÿæˆ

        if matched_question:
            # åŒ¹é…åˆ°é¢„è®¾é—®é¢˜
            answer = matched_question.answer
            matched = True
            is_ai_generated = False
        else:
            # æœªåŒ¹é…åˆ°ï¼Œè°ƒç”¨AIæœåŠ¡ç”Ÿæˆå›ç­”
            from app.core.config import settings

            logger.info(f"å¼€å§‹è°ƒç”¨AIæœåŠ¡ - ç”¨æˆ·é€‰æ‹©æ¨¡å‹: {request.model}, æ·±åº¦æ€è€ƒ: {request.deep_thinking}, é—®é¢˜: {request.question}")

            # æ ¹æ®æ·±åº¦æ€è€ƒæ¨¡å¼å’Œç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ï¼Œç¡®å®šå®é™…ä½¿ç”¨çš„æ¨¡å‹
            if request.deep_thinking:
                # å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼ï¼šä¸ç®¡é€‰æ‹©ä»€ä¹ˆæ¨¡å‹ï¼Œéƒ½ä½¿ç”¨ DEEPSEEK_MODEL
                actual_model_name = settings.DEEPSEEK_MODEL
                actual_model_key = "deepseek"
                logger.info(f"æ·±åº¦æ€è€ƒæ¨¡å¼å·²å¯ç”¨ï¼Œå¼ºåˆ¶ä½¿ç”¨ DeepSeek æ·±åº¦æ€è€ƒæ¨¡å‹: {actual_model_name}")
            else:
                # æœªå¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼ï¼šæ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹å†³å®š
                if request.model == "deepseek":
                    # é€‰æ‹© deepseek ä¸”æœªå¯ç”¨æ·±åº¦æ€è€ƒï¼Œä½¿ç”¨ DEEPSEEK_NOTHINK_MODEL
                    actual_model_name = settings.DEEPSEEK_NOTHINK_MODEL
                    actual_model_key = "deepseek"
                    logger.info(f"ä½¿ç”¨ DeepSeek éæ·±åº¦æ€è€ƒæ¨¡å‹: {actual_model_name}")
                elif request.model == "glm":
                    actual_model_name = settings.GLM_MODEL
                    actual_model_key = "glm"
                elif request.model == "qwen":
                    actual_model_name = settings.QWEN_TEXT_MODEL
                    actual_model_key = "qwen"
                else:
                    # é»˜è®¤ä½¿ç”¨ DEEPSEEK_NOTHINK_MODEL
                    actual_model_name = settings.DEEPSEEK_NOTHINK_MODEL
                    actual_model_key = "deepseek"

            # æ¨¡å‹æ˜ å°„ï¼ˆç”¨äºé™çº§ï¼‰
            model_map = {
                "deepseek": settings.DEEPSEEK_NOTHINK_MODEL if not request.deep_thinking else settings.DEEPSEEK_MODEL,
                "glm": settings.GLM_MODEL,
                "qwen": settings.QWEN_TEXT_MODEL
            }

            # å®šä¹‰æ¨¡å‹é™çº§é¡ºåºï¼ˆå½“å‰æ¨¡å‹å¤±è´¥æ—¶å°è¯•çš„å¤‡é€‰æ¨¡å‹ï¼‰
            # å¦‚æœå¯ç”¨äº†æ·±åº¦æ€è€ƒæ¨¡å¼ï¼Œä¸è¿›è¡Œé™çº§
            if request.deep_thinking:
                fallback_order = {
                    "deepseek": [],  # æ·±åº¦æ€è€ƒæ¨¡å¼ä¸é™çº§
                    "glm": [],
                    "qwen": []
                }
            else:
                fallback_order = {
                    "deepseek": ["glm", "qwen"],
                    "glm": ["deepseek", "qwen"],
                    "qwen": ["deepseek", "glm"]
                }

            # é¦–å…ˆå°è¯•å®é™…é€‰æ‹©çš„æ¨¡å‹
            answer, success = await call_ai_service_with_retry(
                actual_model_key,
                actual_model_name,
                request.question,
                max_retries=2
            )

            used_model = actual_model_key
            selected_model_key = request.model  # ä¿ç•™ç”¨æˆ·åŸå§‹é€‰æ‹©çš„æ¨¡å‹é”®åï¼Œç”¨äºåç»­æç¤º

            # å¦‚æœå¤±è´¥ï¼Œå°è¯•é™çº§åˆ°å…¶ä»–æ¨¡å‹ï¼ˆä»…åœ¨éæ·±åº¦æ€è€ƒæ¨¡å¼ä¸‹ï¼‰
            if not success and not request.deep_thinking:
                logger.warning(f"æ¨¡å‹ {actual_model_key} è°ƒç”¨å¤±è´¥ï¼Œå¼€å§‹å°è¯•é™çº§åˆ°å¤‡é€‰æ¨¡å‹")

                fallback_models = fallback_order.get(actual_model_key, ["deepseek", "glm"])

                for fallback_key in fallback_models:
                    fallback_name = model_map.get(fallback_key)
                    if not fallback_name:
                        continue

                    logger.info(f"å°è¯•é™çº§æ¨¡å‹: {fallback_key} ({fallback_name})")

                    answer, success = await call_ai_service_with_retry(
                        fallback_key,
                        fallback_name,
                        request.question,
                        max_retries=1  # é™çº§æ¨¡å‹åªé‡è¯•1æ¬¡
                    )

                    if success:
                        used_model = fallback_key
                        logger.info(f"æ¨¡å‹é™çº§æˆåŠŸ - ä» {selected_model_key} é™çº§åˆ° {fallback_key}")
                        break

            # å¤„ç†æœ€ç»ˆç»“æœ
            if success and answer:
                matched = False
                is_ai_generated = True

                # å¦‚æœä½¿ç”¨äº†é™çº§æ¨¡å‹ï¼Œåœ¨å›ç­”å‰æ·»åŠ æç¤º
                if used_model != selected_model_key:
                    model_names = {
                        "deepseek": "DeepSeek",
                        "glm": "GLMï¼ˆæ™ºè°±æ¸…è¨€ï¼‰",
                        "qwen": "Qwenï¼ˆé€šä¹‰åƒé—®ï¼‰"
                    }
                    original_name = model_names.get(selected_model_key, selected_model_key)
                    used_name = model_names.get(used_model, used_model)
                    answer = f"[æç¤ºï¼š{original_name}æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨ï¼Œå·²è‡ªåŠ¨åˆ‡æ¢åˆ°{used_name}æ¨¡å‹]\n\n{answer}"

                logger.info(f"AIæœåŠ¡æœ€ç»ˆæˆåŠŸ - ä½¿ç”¨æ¨¡å‹: {used_model}, å›ç­”é•¿åº¦: {len(answer)}")
            else:
                # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
                logger.error(f"æ‰€æœ‰AIæ¨¡å‹å‡è°ƒç”¨å¤±è´¥ - åŸå§‹æ¨¡å‹: {selected_model_key}")

                model_names = {
                    "deepseek": "DeepSeek",
                    "glm": "GLMï¼ˆæ™ºè°±æ¸…è¨€ï¼‰",
                    "qwen": "Qwenï¼ˆé€šä¹‰åƒé—®ï¼‰"
                }
                original_name = model_names.get(selected_model_key, selected_model_key)

                answer = f"æŠ±æ­‰ï¼Œ{original_name}æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨ï¼Œä¸”å¤‡é€‰æ¨¡å‹ä¹Ÿæ— æ³•å“åº”ã€‚\n\nå»ºè®®æ‚¨ï¼š\n1. ç¨åé‡è¯•\n2. å°è¯•åˆ‡æ¢åˆ°å…¶ä»–AIæ¨¡å‹\n3. ä»å·¦ä¾§é¢„è®¾é—®é¢˜ä¸­é€‰æ‹©"
                matched = False
                is_ai_generated = False

        # è·å–å½“å‰åŒ—äº¬æ—¶é—´
        current_time = get_beijing_time()

        # ä¿å­˜å¯¹è¯å†å²ï¼Œæ ‡è®°æ˜¯å¦ç”±AIç”Ÿæˆï¼Œä½¿ç”¨åŒ—äº¬æ—¶é—´
        history = AskHistory(
            session_id=request.session_id,
            question=request.question,
            answer=answer,
            is_ai_generated=is_ai_generated,
            created_at=current_time
        )
        db.add(history)
        await db.commit()

        # æ‰“å°AIå›ç­”æ—¶é—´
        answer_time = get_beijing_time()
        answer_time_str = answer_time.strftime("%Y-%m-%d %H:%M:%S")
        logger.info(f"[AIå›ç­”] æ—¶é—´: {answer_time_str}, å›ç­”é•¿åº¦: {len(answer)}")

        return AskResponse(answer=answer, matched=matched)
    except Exception as e:
        await db.rollback()
        logger.error(f"å¤„ç†æé—®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†æé—®å¤±è´¥: {str(e)}")


@router.get("/ai-agent/sessions", response_model=List[SessionResponse])
async def get_sessions(db: AsyncSession = Depends(get_db)):
    """
    è·å–æ‰€æœ‰å¯¹è¯ä¼šè¯åˆ—è¡¨
    ä¼˜å…ˆä½¿ç”¨AIç”Ÿæˆçš„ç¬¬ä¸€æ¡é—®é¢˜ä½œä¸ºæ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç¬¬ä¸€æ¡æé—®
    """
    try:
        from sqlalchemy import and_

        # è·å–æ‰€æœ‰ä¼šè¯ID
        sessions_stmt = select(AskHistory.session_id).distinct()
        sessions_result = await db.execute(sessions_stmt)
        session_ids = [row[0] for row in sessions_result.all()]

        sessions = []
        for session_id in session_ids:
            # ä¼˜å…ˆæŸ¥æ‰¾AIç”Ÿæˆçš„ç¬¬ä¸€æ¡è®°å½•
            ai_stmt = select(AskHistory).where(
                and_(
                    AskHistory.session_id == session_id,
                    AskHistory.is_ai_generated == True
                )
            ).order_by(AskHistory.created_at.asc()).limit(1)

            ai_result = await db.execute(ai_stmt)
            ai_record = ai_result.scalar_one_or_none()

            if ai_record:
                # æ‰¾åˆ°AIç”Ÿæˆçš„è®°å½•ï¼Œä½¿ç”¨å®ƒä½œä¸ºæ ‡é¢˜
                first_question = ai_record.question
                created_at = ai_record.created_at
            else:
                # æ²¡æœ‰AIç”Ÿæˆçš„è®°å½•ï¼Œä½¿ç”¨ç¬¬ä¸€æ¡æé—®
                first_stmt = select(AskHistory).where(
                    AskHistory.session_id == session_id
                ).order_by(AskHistory.created_at.asc()).limit(1)

                first_result = await db.execute(first_stmt)
                first_record = first_result.scalar_one_or_none()

                if first_record:
                    first_question = first_record.question
                    created_at = first_record.created_at
                else:
                    continue  # è·³è¿‡ç©ºä¼šè¯

            # ç»Ÿè®¡æ¶ˆæ¯æ•°é‡
            count_stmt = select(func.count(AskHistory.id)).where(
                AskHistory.session_id == session_id
            )
            count_result = await db.execute(count_stmt)
            message_count = count_result.scalar()

            sessions.append({
                'session_id': session_id,
                'first_question': first_question,
                'created_at': created_at,
                'message_count': message_count
            })

        # æŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åº
        sessions.sort(key=lambda x: x['created_at'], reverse=True)

        return [
            SessionResponse(
                session_id=s['session_id'],
                first_question=s['first_question'],
                created_at=s['created_at'],
                message_count=s['message_count']
            )
            for s in sessions
        ]
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/ai-agent/sessions/{session_id}", response_model=List[HistoryResponse])
async def get_session_history(session_id: str, db: AsyncSession = Depends(get_db)):
    """
    è·å–æŒ‡å®šä¼šè¯çš„å®Œæ•´å¯¹è¯å†å²
    """
    try:
        stmt = select(AskHistory).where(
            AskHistory.session_id == session_id
        ).order_by(AskHistory.created_at.asc())

        result = await db.execute(stmt)
        history = result.scalars().all()

        return [
            HistoryResponse(
                id=h.id,
                question=h.question,
                answer=h.answer,
                created_at=h.created_at
            )
            for h in history
        ]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢ä¼šè¯å†å²å¤±è´¥: {str(e)}")


@router.post("/ai-agent/sessions")
async def create_session():
    """
    åˆ›å»ºæ–°çš„å¯¹è¯ä¼šè¯
    è¿”å›æ–°çš„session_id
    """
    try:
        new_session_id = str(uuid.uuid4())
        return {"session_id": new_session_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}")

