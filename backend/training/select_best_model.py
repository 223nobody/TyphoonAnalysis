"""
é€‰æ‹©æœ€ä½³æ¨¡å‹è„šæœ¬

è‡ªåŠ¨è¯„ä¼°æ‰€æœ‰ä¿å­˜çš„æ¨¡å‹ï¼Œé€‰æ‹©æ€§èƒ½æœ€å¥½çš„ä¸€ä¸ª
"""
import logging
from pathlib import Path
import torch
import numpy as np
from torch.utils.data import DataLoader

from app.services.prediction.data.dataset import CSVTyphoonDataset, TyphoonDataCollator
from app.services.prediction.models.lstm_model import LSTMTyphoonModel
from app.services.prediction.models.loss_functions import TyphoonPredictionLoss

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def evaluate_single_model(model_path: Path, device: torch.device, val_loader: DataLoader) -> dict:
    """è¯„ä¼°å•ä¸ªæ¨¡å‹"""
    logger.info(f"\nè¯„ä¼°æ¨¡å‹: {model_path.name}")
    
    try:
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = torch.load(model_path, map_location=device)
        
        # åˆå§‹åŒ–æ¨¡å‹
        model = LSTMTyphoonModel(
            input_size=10,
            hidden_size=128,
            num_layers=3,
            output_size=4,
            prediction_steps=8,
            dropout=0.2,
            attention_heads=8
        ).to(device)
        
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            logger.warning(f"âš ï¸ {model_path.name}: æ²¡æœ‰æ¨¡å‹æƒé‡")
            return None
        
        model.eval()
        
        # è¯„ä¼°
        criterion = TyphoonPredictionLoss()
        total_loss = 0.0
        total_samples = 0
        
        with torch.no_grad():
            for inputs, targets in val_loader:
                inputs = inputs.to(device)
                targets = targets.to(device)
                
                outputs, _, _ = model(inputs)
                loss = criterion(outputs, targets)
                
                if not torch.isnan(loss):
                    total_loss += loss.item() * inputs.size(0)
                    total_samples += inputs.size(0)
        
        if total_samples > 0:
            avg_loss = total_loss / total_samples
            
            # è·å–è®­ç»ƒå†å²
            train_losses = checkpoint.get('train_losses', [])
            val_losses = checkpoint.get('val_losses', [])
            
            result = {
                'name': model_path.name,
                'path': str(model_path),
                'val_loss': avg_loss,
                'final_train_loss': train_losses[-1] if train_losses else None,
                'epochs_trained': len(train_losses),
                'total_samples': total_samples
            }
            
            logger.info(f"  âœ… éªŒè¯æŸå¤±: {avg_loss:.6f}")
            logger.info(f"  ğŸ“Š è®­ç»ƒè½®æ•°: {result['epochs_trained']}")
            
            return result
        else:
            logger.warning(f"âš ï¸ {model_path.name}: æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬")
            return None
            
    except Exception as e:
        logger.error(f"âŒ è¯„ä¼° {model_path.name} å¤±è´¥: {e}")
        return None


def select_best_model(models_dir: str = './models', device: str = 'cuda'):
    """é€‰æ‹©æœ€ä½³æ¨¡å‹"""
    logger.info("=" * 70)
    logger.info("é€‰æ‹©æœ€ä½³æ¨¡å‹")
    logger.info("=" * 70)
    
    device = torch.device(device if torch.cuda.is_available() else 'cpu')
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. åˆ›å»ºéªŒè¯æ•°æ®é›†
    logger.info("\nåˆ›å»ºéªŒè¯æ•°æ®é›†...")
    val_dataset = CSVTyphoonDataset(
        start_year=2018,
        end_year=2020,
        sequence_length=12,
        prediction_steps=8
    )
    
    logger.info(f"éªŒè¯æ•°æ®é›†å¤§å°: {len(val_dataset)} ä¸ªæ ·æœ¬")
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=32,
        shuffle=False,
        collate_fn=TyphoonDataCollator(),
        num_workers=0
    )
    
    # 2. æŸ¥æ‰¾æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
    models_path = Path(models_dir)
    if not models_path.exists():
        logger.error(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {models_dir}")
        return
    
    model_files = list(models_path.glob('*.pth'))
    if not model_files:
        logger.error(f"æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {models_dir}")
        return
    
    logger.info(f"\næ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶:")
    for f in model_files:
        logger.info(f"  - {f.name}")
    
    # 3. è¯„ä¼°æ‰€æœ‰æ¨¡å‹
    logger.info("\n" + "=" * 70)
    logger.info("å¼€å§‹è¯„ä¼°æ‰€æœ‰æ¨¡å‹...")
    logger.info("=" * 70)
    
    results = []
    for model_file in model_files:
        result = evaluate_single_model(model_file, device, val_loader)
        if result:
            results.append(result)
    
    if not results:
        logger.error("âŒ æ²¡æœ‰æ¨¡å‹è¯„ä¼°æˆåŠŸ")
        return
    
    # 4. æ’åºå¹¶é€‰æ‹©æœ€ä½³æ¨¡å‹
    results.sort(key=lambda x: x['val_loss'])
    
    logger.info("\n" + "=" * 70)
    logger.info("è¯„ä¼°ç»“æœæ’å")
    logger.info("=" * 70)
    
    for i, result in enumerate(results, 1):
        logger.info(f"\n[{i}] {result['name']}")
        logger.info(f"    éªŒè¯æŸå¤±: {result['val_loss']:.6f}")
        logger.info(f"    è®­ç»ƒè½®æ•°: {result['epochs_trained']}")
        logger.info(f"    æœ€ç»ˆè®­ç»ƒæŸå¤±: {result['final_train_loss']:.6f}" if result['final_train_loss'] else "    æœ€ç»ˆè®­ç»ƒæŸå¤±: N/A")
    
    # 5. æ¨èæœ€ä½³æ¨¡å‹
    best_model = results[0]
    
    logger.info("\n" + "=" * 70)
    logger.info("ğŸ† æœ€ä½³æ¨¡å‹æ¨è")
    logger.info("=" * 70)
    logger.info(f"æ¨¡å‹åç§°: {best_model['name']}")
    logger.info(f"æ¨¡å‹è·¯å¾„: {best_model['path']}")
    logger.info(f"éªŒè¯æŸå¤±: {best_model['val_loss']:.6f}")
    logger.info(f"è®­ç»ƒè½®æ•°: {best_model['epochs_trained']}")
    
    # 6. åˆ›å»ºæœ€ä½³æ¨¡å‹é“¾æ¥/å‰¯æœ¬
    best_model_link = models_path / 'best_model.pth'
    try:
        import shutil
        shutil.copy(best_model['path'], str(best_model_link))
        logger.info(f"\nâœ… æœ€ä½³æ¨¡å‹å·²å¤åˆ¶åˆ°: {best_model_link}")
    except Exception as e:
        logger.warning(f"âš ï¸ å¤åˆ¶æœ€ä½³æ¨¡å‹å¤±è´¥: {e}")
    
    logger.info("\n" + "=" * 70)
    logger.info("ä½¿ç”¨å»ºè®®")
    logger.info("=" * 70)
    logger.info(f"åœ¨ä»£ç ä¸­ä½¿ç”¨æœ€ä½³æ¨¡å‹:")
    logger.info(f"  predictor = TyphoonPredictor(model_path='{best_model['path']}', device='cuda')")
    logger.info(f"\næˆ–è€…ä½¿ç”¨å¿«æ·æ–¹å¼:")
    logger.info(f"  predictor = TyphoonPredictor(model_path='./models/best_model.pth', device='cuda')")
    
    return best_model


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='é€‰æ‹©æœ€ä½³æ¨¡å‹')
    parser.add_argument('--models-dir', type=str, default='./models',
                        help='æ¨¡å‹ç›®å½•è·¯å¾„')
    parser.add_argument('--device', type=str, default='cuda',
                        help='è®¾å¤‡ (cpu/cuda)')
    
    args = parser.parse_args()
    
    select_best_model(args.models_dir, args.device)
